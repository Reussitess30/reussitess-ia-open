import os
from llama_cpp import Llama

# Initialisation du moteur sup√©rieur local
llm = Llama(model_path="./model_reussitess.gguf", verbose=False)

def scanner_fichier(nom_fichier):
    if not os.path.exists(nom_fichier):
        return f"Erreur : {nom_fichier} introuvable."
    
    print(f"üîé Les 100 IA analysent {nom_fichier}...")
    with open(nom_fichier, 'r') as f:
        contenu = f.read()

    # L'IA cherche des vuln√©rabilit√©s sans API externe
    prompt = f"Analyse ce code pour trouver des failles de s√©curit√© ou des fonctions cach√©es : {contenu}"
    
    analyse = llm(f"<|user|>\n{prompt}</s>\n<|assistant|>\n", max_tokens=200)
    return analyse['choices'][0]['text'].strip()

# Scan du fichier package.json pour v√©rifier l'int√©grit√© de Reussitess¬©
rapport = scanner_fichier("package.json")
print("\n[Rapport de S√©curit√© Reussitess¬©] :")
print(rapport)
